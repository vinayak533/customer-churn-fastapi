# ğŸ“‰ Customer Churn Prediction System with FastAPI, Streamlit & Ollama

## ğŸ“Œ Summary

This project is an end-to-end Machine Learning deployment that predicts customer churn using an XGBoost model and provides AI-powered explanations using a local LLM (Gemma 2B via Ollama). The system includes a FastAPI backend, Streamlit frontend, Docker deployment, and CI/CD pipeline for production-ready ML serving.

---

## ğŸ› ï¸ Technologies Used

* Python
* Scikit-learn / XGBoost
* FastAPI
* Streamlit
* Ollama (Gemma 2B LLM)
* Docker & Docker Compose
* GitHub Actions (CI/CD)
* Pandas & NumPy

---

## âœ¨ Features

* Predicts customer churn (Yes / No)
* Returns churn probability score
* AI-generated explanations for predictions using LLM
* REST API for model inference
* Interactive Streamlit web interface
* Dockerized deployment environment
* CI/CD pipeline with GitHub Actions
* Modular backend and frontend architecture

---

## âŒ¨ï¸ Keyboard Shortcuts

```
Ctrl + C   â†’ Stop server
Enter      â†’ Submit command
Up Arrow   â†’ Reuse previous command
```

---

## âš™ï¸ Process

```
1. User enters customer details in Streamlit UI
2. Data is sent to FastAPI backend
3. ML model predicts churn probability
4. Ollama LLM generates explanation
5. Results are displayed to the user
```

---

## ğŸ—ï¸ How I Built It

```
- Trained a customer churn prediction model using XGBoost
- Saved model and encoders using pickle
- Built FastAPI backend for inference API
- Created Streamlit UI for user interaction
- Integrated Ollama (Gemma 2B) for AI explanations
- Containerized the application using Docker
- Implemented CI/CD pipeline using GitHub Actions
```

---

## ğŸ“š What I Learned

```
- End-to-end ML deployment workflow
- FastAPI backend development for ML models
- Streamlit dashboard creation
- Docker containerization and orchestration
- CI/CD automation using GitHub Actions
- Integrating LLMs into traditional ML systems
- Model serving and API design
```

---

## ğŸš€ How It Could Be Improved

```
- Deploy to cloud platforms (AWS, GCP, Azure)
- Add user authentication system
- Implement model monitoring and logging
- Add real-time database integration
- Improve UI/UX with advanced visualization
- Use larger LLM for more accurate explanations
```

---

## â–¶ï¸ How to Run the Project

### Clone Repository

```bash
git clone https://github.com/yourusername/customer-churn-fastapi.git
cd customer-churn-fastapi
```

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Start FastAPI Server

```bash
uvicorn app:app --reload
```

API Docs:
http://127.0.0.1:8000/docs

### Start Streamlit App

```bash
streamlit run streamlit_app.py
```

---

## ğŸ³ Run with Docker

```bash
docker-compose up --build
```

FastAPI: http://localhost:8000
Streamlit: http://localhost:8501

---

## ğŸ“‚ Project Structure

```
customer-churn-fastapi/
â”‚
â”œâ”€â”€ app.py                     # FastAPI backend
â”œâ”€â”€ streamlit_app.py           # Streamlit frontend
â”œâ”€â”€ customer_churn_model.pkl   # Trained ML model
â”œâ”€â”€ encoders.pkl               # Feature encoders
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci.yml                 # CI/CD pipeline
â”‚
â””â”€â”€ README.md
```

---

## â­ About

A production-ready machine learning system for predicting customer churn with AI-powered explanations using FastAPI, Streamlit, Docker, CI/CD, and Ollama.
